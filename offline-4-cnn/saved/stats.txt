run#1
=====
saved_model -> none
random_seed -> 42
dataset -> 10k
preprocessing -> resized to 28x28, inverted, normalized
test ratio -> 0.2
batch_size -> 16
epoch -> 5
learning_rate -> 0.001
xavier initialization -> gaussian

per epoch time -> ~1.25 min

training stats ->
validation accuracy -> 0.4475

run#2
=====
saved_model -> model_45000-samples_0.2-test_ratio_42-random_seed_10-epochs_64-batch_size.pkl
random_seed -> 42
dataset -> 45k
preprocessing -> resized to 28x28, inverted, normalized
test ratio -> 0.2
batch_size -> 64
epoch -> 10 
learning_rate -> 0.001
xavier initialization -> gaussian

per epoch time -> ~5.75 min

training stats ->
per epoch train loss: [2.222519509119432, 1.8497343331218403, 1.705211767313102, 1.6000546627890102, 1.5149414038911098, 1.4426852446377654, 1.3808518750993641, 1.3269884910244072, 1.2802714053516484, 1.2390756026736032]
per epoch train accuracy: [0.2540331678700361, 0.3740974729241877, 0.42782603790613716, 0.46903203971119134, 0.4981949458483754, 0.5216042418772563, 0.5427008122743683, 0.5603000902527075, 0.5759814981949458, 0.5894347924187726]
per epoch validation loss: [1.9566468183127, 1.7829102118346183, 1.6695992771892805, 1.5795540644751485, 1.5047646265512666, 1.441682964586125, 1.388048903730089, 1.340875335634543, 1.2996116938535507, 1.2629538607992115]
per epoch validation accuracy: [0.3362263300270514, 0.3978809738503156, 0.4386834986474301, 0.4659603246167719, 0.49222272317403065, 0.5142019837691614, 0.5320108205590622, 0.5464382326420198, 0.5603020739404869, 0.5712353471596032]
per epoch validation f1 score: [0.3276463926469705, 0.39122037745862853, 0.4331381205627437, 0.46092060038825255, 0.48771577402478916, 0.5099725559344146, 0.5282690381042883, 0.5433156397039256, 0.5578777568361163, 0.5694976768881429]

testing stats ->
testing dataset -> d
testing loss -> 1.8904589618814358
testing accuracy -> 0.47625595892922623
testing f1 score -> 0.42287761174575245
confusion matrix:
[[596 259  38 101   0  43   0  26  23  21]
 [ 15 863  50  49   0  18   1  34  18  59]
 [ 20 147 812  15   0  17   0  55  28  13]
 [ 21  87  22 887   0  39   2  20  24   5]
 [ 69 435 219  24   0 164   1 122  49  24]
 [ 78 250  71 215   0 350   0  69  48  26]
 [  9 134  15 783   0  48  19  24  28   8]
 [ 14  88 107  34   0  34   1 756  33   8]
 [ 12 155  36  91   0  46   2  22 703  19]
 [ 26 460  45  97   0  64   2 102  32 209]]

 comment -> problem on class 4 (5). model didn't predict 1 single class 4 (5) image correctly. also poor on class 6 (7).

run#3
=====
saved_model -> oversized (in drive) -> model_45000-samples_0.2-test_ratio_0-random_seed_10-epochs_64-batch_size.pkl
random_seed -> 0
dataset -> 45k
preprocessing -> resized to 28x28, inverted, normalized
test ratio -> 0.2
batch_size -> 64
epoch -> 10
learning_rate -> 0.001
xavier initialization -> uniform

per epoch time -> ~5.75 min

training stats ->
per epoch train loss: [2.330989642940702, 1.9180169727650789, 1.7568770637045728, 1.6437397499969713, 1.5544233006549242, 1.4794012789635544, 1.4148354620098933, 1.3591589197911378, 1.3106342805863183, 1.2677703480971367]
per epoch train accuracy: [0.22055505415162455, 0.3390399368231047, 0.4033167870036101, 0.44418434115523464, 0.4778034747292419, 0.5040049638989169, 0.5258348375451264, 0.5427572202166066, 0.5607795577617328, 0.5739508122743683]
per epoch validation loss: [2.040678415877962, 1.8384092364966194, 1.7111267534845997, 1.6140057325194284, 1.5353313625875202, 1.4695360471939811, 1.4133205171253986, 1.3654266725300563, 1.322751748080419, 1.284672191964844]
per epoch validation accuracy: [0.2886609558160505, 0.3658701532912534, 0.4109558160504959, 0.44860234445446345, 0.47666816952209196, 0.5029305680793508, 0.5213029756537421, 0.5429440937781785, 0.5584986474301172, 0.5703336339044184]
per epoch validation f1 score: [0.2780807923727854, 0.35719864829000586, 0.40469005628866783, 0.44333229706314, 0.4720422025389016, 0.49859637315394484, 0.5171128606237885, 0.5389277967049405, 0.554984356861995, 0.5676130724765154]
confusion matrix:
[[460  19  13  56  88  98  18  45  31  62]
 [ 16 394  81  28  58  24  17  34  34 194]
 [  6  73 499   5 115  28   9  56  35  66]
 [ 18   8   2 558   8  55 149  26  37  29]
 [ 17  26  58   5 582  63  10  57  20  55]
 [ 76   9  26  93 116 405  35  39  26  64]
 [ 18   9  10 300  10  52 376  31  46  40]
 [ 21   5  21  17  51  29  16 666  25  37]
 [ 15   3  13  14  30  12  35  26 689  40]
 [ 28 105  59  46  81  22  21  57  31 431]]

testing stats ->
testing dataset -> d
testing loss: 1.5039211833218273
testing accuracy: 0.49624129079574625
testing f1 score: 0.4914966361546166
confusion matrix:
[[515  21  11  85  58 111  43  78  41 144]
 [  7 450  38  45  26   4  40  75  28 394]
 [ 12  82 543   9  63  27  40 132  57 142]
 [ 10   3   3 722   3  15 198  83  31  39]
 [ 47  39  36  37 387  27  23 248  29 234]
 [ 76  22  22 248  64 195 131 122  56 171]
 [ 12   6  11 407   2   6 479  70  40  35]
 [ 12  13  18  34  41   3  21 845  28  60]
 [ 23  10   8  25  42  16  41  67 784  70]
 [  8  90  18 159  30  14  46 149  30 493]]


run#4
=====
saved_model -> model_45000-samples_0.2-test_ratio_0-random_seed_10-epochs_256-batch_size.pkl
random_seed -> 0
dataset -> 45k
preprocessing -> resized to 28x28, inverted, normalized
test ratio -> 0.2
batch_size -> 256
epoch -> 10
learning_rate -> 0.001
xavier initialization -> gaussian

per epoch time -> ~5 min

training stats ->
per epoch train loss: [2.632741855338261, 2.1841600102135508, 2.047953771757429, 1.9681120211742347, 1.908268015716839, 1.8583216490137395, 1.8149532017777914, 1.776116174259716, 1.7405906368650315, 1.708162123615424]
per epoch train accuracy: [0.1735167572463768, 0.24708446557971014, 0.2951766304347826, 0.32670969202898553, 0.3524682971014493, 0.373726222826087, 0.39076653079710144, 0.40636322463768115, 0.4194972826086957, 0.4329993206521739]
per epoch validation loss: [2.2950712246396225, 2.1041423874615592, 2.0095542150281225, 1.9440545345249312, 1.8909662760808568, 1.8456160005590359, 1.8057849056512512, 1.769996627154461, 1.7375928780443322, 1.7080749241671036]
per epoch validation accuracy: [0.21336789900811542, 0.2756988277727683, 0.31379621280432823, 0.33915689810640215, 0.36158701532912535, 0.37905770964833185, 0.3939359783588819, 0.40768710550045084, 0.42177637511271415, 0.4331605049594229]
per epoch validation f1 score: [0.21171769594751363, 0.2727943832752377, 0.3102109508725762, 0.33589599828672495, 0.3587711413462479, 0.3764752881769018, 0.39147289460650686, 0.4058970491289358, 0.4200875111978103, 0.43149411123077897]
confusion matrix:
[[331  72  42  85  82  51  75  53  39  60]
 [ 39 364  75  52  72  12  52  45  51 118]
 [ 26 112 408  17  98  22  40  56  48  65]
 [ 32  24  21 425  31  50 195  49  19  44]
 [ 19  32  58  27 399 114  50  75  61  58]
 [ 55  24  30  94 115 272 100  92  36  71]
 [ 20  29  33 192  38  75 338  76  30  61]
 [ 14  17  29  69 100  40  33 508  60  18]
 [ 28  38  33  20  83  13  59  46 525  32]
 [ 39 138  83  79  50  29  58  72  60 273]]

testing stats ->
testing dataset -> d

run#5
=====
model -> model_45000-samples_0.2-test_ratio_0-random_seed_10-epochs_64-batch_size.pkl
random_seed -> 0
dataset -> 45k
preprocessing -> resized to 28x28, inverted, normalized, dilated
test ratio -> 0.2
batch_size -> 64
epoch -> 10
learning_rate -> 0.001
xavier initialization -> gaussian

per epoch time -> ~5 min

training stats ->
per epoch train loss: [2.089486133219296, 1.613190955666567, 1.4376249184404257, 1.3189824952812934, 1.2283462933250422, 1.1561687842055766, 1.09715678334405, 1.0509964763478006, 1.0218856843849484, 1.0436015312200937]
per epoch train accuracy: [0.3237533844765343, 0.4693986913357401, 0.5317576714801444, 0.5711868231046932, 0.6025214350180506, 0.6253102436823105, 0.64420690433213, 0.657293546931408, 0.6647111913357401, 0.6559397563176895]
per epoch validation loss: [1.7331558636381694, 1.5190951120948826, 1.385040384202805, 1.2873264141976732, 1.209628486554879, 1.1405823131360124, 1.0823126539884522, 1.0353820370723603, 1.0031713294935098, 1.0315487425620369]
per epoch validation accuracy: [0.4250450856627592, 0.4985347159603246, 0.5475653742110009, 0.5829576194770063, 0.609107303877367, 0.6321009918845807, 0.653629395852119, 0.6709873760144274, 0.6770739404869252, 0.6541929666366095]
per epoch validation f1 score: [0.41738531351405406, 0.493260867426274, 0.5443367906243745, 0.5813668518002068, 0.608957683794777, 0.6322177626929479, 0.6539559730368617, 0.671570000187807, 0.6781310351983522, 0.6514211685391125]
confusion matrix:
[[618  19   6  44   8  53  49  27  32  34]
 [ 15 547  14  10   8   5  33  26  27 195]
 [ 26  74 564   3  10  18  20  60  21  96]
 [ 22   7   3 429   0  24 328  16  22  39]
 [ 26  12   9   8 374 156  36 118  92  62]
 [ 72   5  11  37  19 476 170  29  31  39]
 [  6   3   4  69   5  26 685  21  29  44]
 [  5   2   4  23   8  17  10 777  22  20]
 [  7   6   1   3   5   5  24  18 787  21]
 [  7 122  27  12   5  10  73  34  44 547]]

testing stats ->
testing dataset -> d
testing loss: 1.3363585333265506
testing accuracy: 0.5835166850018335
testing f1 score: 0.5688275415987685
confusion matrix:
[[755  22   1  59   3  60  20  48  57  82]
 [ 18 587  11  18   1   5  18  45  44 360]
 [ 34  35 622   7   5  11  26  84  56 227]
 [ 38   3   7 670   0   7 223  40  38  81]
 [ 40   7   4  12 251  37  34 233 217 272]
 [126   3   7 107   6 217 239  96 120 186]
 [ 24   2   4 218   1   6 661  39  42  71]
 [ 10  10   4  23   3   4  12 942  37  30]
 [  8   1   1   8   5   8   8  53 960  34]
 [  8  76  10  52   1  12  53  80  45 700]]